{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Digit recognition using Tensorflow (thinning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blob.shape= (1, 1, 28, 28)\n",
      "y_predict= [3]\n",
      "blob.shape= (1, 1, 28, 28)\n",
      "y_predict= [2]\n",
      "blob.shape= (1, 1, 28, 28)\n",
      "y_predict= [3]\n",
      "blob.shape= (1, 1, 28, 28)\n",
      "y_predict= [7]\n",
      "blob.shape= (1, 1, 28, 28)\n",
      "y_predict= [5]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#1\n",
    "net = cv2.dnn.readNetFromTensorflow('./dnn/MNIST_MLP_frozen_graph.pb')\n",
    "#net = cv2.dnn.readNetFromTensorflow('./dnn/MINIST_CNN_frozen_graph2.pb')\n",
    "\n",
    "#2\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.circle(dst, (x, y), 15, (255, 255, 255), -1)\n",
    "    cv2.imshow('dst', dst)\n",
    "\n",
    "def thinning(A):\n",
    "    skel_dst = np.zeros(A.shape, np.uint8)\n",
    "    B = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize = (3, 3))\n",
    "    done = True\n",
    "    while done:\n",
    "        erode = cv2.erode(A, B)\n",
    "        opening = cv2.morphologyEx(erode, cv2.MORPH_OPEN, B)\n",
    "        tmp = cv2.subtract(erode, opening)    # cv2.absdiff(erode, opening)\n",
    "        skel_dst = cv2.bitwise_or(skel_dst, tmp)\n",
    "        A = erode.copy()\n",
    "        done = cv2.countNonZero(A) != 0\n",
    "    skel_dst = cv2.dilate(skel_dst, None, 4)    \n",
    "    skel_dst = cv2.erode(skel_dst, None, 5)\n",
    "    return skel_dst\n",
    "           \n",
    "dst  = np.zeros(shape=(512, 512, 3), dtype=np.uint8)\n",
    "cv2.namedWindow('dst')\n",
    "cv2.setMouseCallback('dst', onMouse)\n",
    "\n",
    "\n",
    "mode   = cv2.RETR_EXTERNAL\n",
    "method = cv2.CHAIN_APPROX_SIMPLE\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "x_img = np.zeros(shape=(28, 28), dtype=np.uint8)\n",
    "\n",
    "#3\n",
    "while True:\n",
    "    key = cv2.waitKey(25)    \n",
    "    if key == 27: \n",
    "        break;\n",
    "    elif key == ord('r'):\n",
    "        dst[:,:] = 0\n",
    "        cv2.imshow('dst',dst)\n",
    "    elif key == ord(' '):\n",
    "        gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "        _, contours, _ = cv2.findContours(gray, mode, method)\n",
    "\n",
    "        for i, cnt in enumerate(contours):\n",
    "#3-1\n",
    "            x, y, width, height = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(dst, (x, y), (x+width, y+height), (0,0,255), 2)\n",
    "            cx, cy = x + width/2, y + height/2\n",
    "            if width > height:\n",
    "                r = width/2\n",
    "            else:\n",
    "                r = height/2            \n",
    "            cx, cy, r= int(cx), int(cy), int(r)\n",
    "            img = gray[cy-r:cy+r, cx-r:cx+r]\n",
    "            img = thinning(img)\n",
    "            cv2.imshow('thinning', img)\n",
    "            img = cv2.resize(img, dsize=(20, 20),interpolation=cv2.INTER_AREA)\n",
    "            ret, img = cv2.threshold(img, 10, 255, cv2.THRESH_BINARY)\n",
    "            x_img[:,:] = 0\n",
    "            x_img[4:24, 4:24] = img\n",
    "            x_img = cv2.dilate(x_img, None, 2)\n",
    "            x_img = cv2.erode(x_img, None, 4)\n",
    "            x_img1 = thinning(x_img)\n",
    "            cv2.imshow('x_img', x_img)\n",
    "#3-2\n",
    "            blob = cv2.dnn.blobFromImage(x_img) # blob.shape=(1, 1, 28, 28)\n",
    "            print('blob.shape=', blob.shape)\n",
    "\n",
    "            net.setInput(blob)\n",
    "            res = net.forward()\n",
    "            y_predict = np.argmax(res, axis = 1)\n",
    "            print('y_predict=', y_predict)\n",
    "            digit = int(y_predict[0])\n",
    "            cv2.putText(dst, str(digit), (x, y), font, 3, (255,0,0), 5)\n",
    "        \n",
    "        cv2.imshow('dst',dst)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Face and Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "faceCascade= cv2.CascadeClassifier(\n",
    "      './haarcascades/haarcascade_frontalface_default.xml')\n",
    "eyeCascade = cv2.CascadeClassifier(\n",
    "    './haarcascades/haarcascade_eye.xml')\n",
    "\n",
    "src = cv2.imread('./data/lena.jpg')\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "faces = faceCascade.detectMultiScale(gray, 1.1, 3) #(gray, 1.1, 0)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(src, (x,y),(x+w, y+h),(255,0,0), 2)\n",
    "    \n",
    "    roi_gray  = gray[y:y+h, x:x+w]\n",
    "    roi_color = src[y:y+h, x:x+w]\n",
    "    \n",
    "    eyes = eyeCascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        \n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Face Detection on YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title =  참이슬 아이유 X 박서준 바이럴영상(30\")\n",
      "best.resolution 640x360\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    " pip install youtube_dl\n",
    " pip install pafy\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2, pafy\n",
    "\n",
    "faceCascade= cv2.CascadeClassifier(\n",
    "      './haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "url = 'https://www.youtube.com/watch?v=S_0ikqqccJs'\n",
    "video = pafy.new(url)\n",
    "print('title = ', video.title)\n",
    "\n",
    "best = video.getbest(preftype='webm')\n",
    "print('best.resolution', best.resolution)\n",
    "\n",
    "file = best.download(filepath=\"./data/demovideo2.\" + best.extension)\n",
    "cap = cv2.VideoCapture(file)\n",
    "#cap=cv2.VideoCapture(best.url)  ### I want to make an url object but failed\n",
    "\n",
    "while(True):\n",
    "        retval, frame = cap.read()\n",
    "        if not retval:\n",
    "                break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = faceCascade.detectMultiScale(gray) #minSize=(50, 50)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x,y),(x+w, y+h),(255,0,0), 2)           \n",
    "        cv2.imshow('frame',frame)\n",
    " \n",
    "        key = cv2.waitKey(25)\n",
    "        if key == 27: # Esc\n",
    "                break\n",
    "                \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 face recognition with AT&T Face Database 1: EigenFaceRecognizer, FisherFaceRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_faces.shape= (320, 10304)\n",
      "train_labels.shape= (320,)\n",
      "test_faces.shape= (80, 10304)\n",
      "test_labels.shape= (80,)\n",
      "eigenFace.shape= (320, 10304)\n",
      "test_labels=20: predicted:20, confidence=2015.8359348595566\n",
      "test_labels=15: predicted:15, confidence=1121.1869835189796\n",
      "test_labels=26: predicted:26, confidence=1275.1992785732932\n",
      "test_labels=33: predicted:33, confidence=3076.704885172979\n",
      "test_labels=38: predicted:38, confidence=2466.7371983988214\n",
      "test_labels=21: predicted:21, confidence=2678.4209967532556\n",
      "test_labels=32: predicted:32, confidence=2515.5599295133247\n",
      "test_labels=34: predicted:34, confidence=2074.356117871548\n",
      "test_labels=0: predicted:0, confidence=3474.3619948362534\n",
      "test_labels=28: predicted:28, confidence=2123.33104098201\n",
      "test_labels=5: predicted:5, confidence=2562.925080313562\n",
      "test_labels=4: predicted:4, confidence=1333.2051538304086\n",
      "test_labels=3: predicted:3, confidence=2273.283420728049\n",
      "test_labels=28: predicted:28, confidence=2909.4165933806676\n",
      "test_labels=22: predicted:22, confidence=1592.0309047611368\n",
      "test_labels=19: predicted:19, confidence=2950.2346779099885\n",
      "test_labels=23: predicted:23, confidence=2353.2001696135444\n",
      "test_labels=30: predicted:30, confidence=2602.709179666726\n",
      "test_labels=10: predicted:10, confidence=2570.1592715907004\n",
      "test_labels=21: predicted:21, confidence=1975.4773237257489\n",
      "test_labels=6: predicted:6, confidence=1753.8851087648925\n",
      "test_labels=32: predicted:32, confidence=2039.3612935915319\n",
      "test_labels=38: predicted:38, confidence=1790.3268015608583\n",
      "test_labels=2: predicted:2, confidence=2609.206918306758\n",
      "test_labels=9: predicted:9, confidence=1749.132961643483\n",
      "test_labels=16: predicted:16, confidence=1883.2334802985877\n",
      "test_labels=31: predicted:31, confidence=2329.3215177263346\n",
      "test_labels=38: predicted:38, confidence=1465.6717979174468\n",
      "test_labels=35: predicted:35, confidence=1253.322830766444\n",
      "test_labels=10: predicted:10, confidence=1436.0661313184041\n",
      "test_labels=3: predicted:3, confidence=2531.201982215048\n",
      "test_labels=37: predicted:37, confidence=1956.8731722960056\n",
      "test_labels=2: predicted:2, confidence=2504.63443767402\n",
      "test_labels=9: predicted:9, confidence=1859.8096727044315\n",
      "test_labels=8: predicted:8, confidence=2487.4977158984707\n",
      "test_labels=30: predicted:30, confidence=2795.6330136788347\n",
      "test_labels=34: predicted:34, confidence=3086.2518223627994\n",
      "test_labels=8: predicted:8, confidence=2089.4276974151057\n",
      "test_labels=12: predicted:12, confidence=2124.259854468171\n",
      "test_labels=26: predicted:26, confidence=2862.9142881722264\n",
      "test_labels=22: predicted:22, confidence=2337.204412608662\n",
      "test_labels=33: predicted:33, confidence=1602.34512183485\n",
      "test_labels=34: predicted:35, confidence=2851.203006635911\n",
      "test_labels=23: predicted:23, confidence=1979.2854298981404\n",
      "test_labels=13: predicted:13, confidence=1716.7045817878518\n",
      "test_labels=30: predicted:30, confidence=1991.1163019748467\n",
      "test_labels=25: predicted:25, confidence=2081.6195797825453\n",
      "test_labels=26: predicted:26, confidence=2019.5939663319537\n",
      "test_labels=37: predicted:37, confidence=2561.6208225887694\n",
      "test_labels=30: predicted:30, confidence=1988.441519879742\n",
      "test_labels=39: predicted:39, confidence=2643.111565453415\n",
      "test_labels=28: predicted:28, confidence=3738.8282301614013\n",
      "test_labels=5: predicted:5, confidence=2265.832575529842\n",
      "test_labels=35: predicted:35, confidence=1690.3471453668326\n",
      "test_labels=18: predicted:18, confidence=1406.4905503482314\n",
      "test_labels=15: predicted:15, confidence=1879.5180074324185\n",
      "test_labels=25: predicted:25, confidence=2177.514081339098\n",
      "test_labels=39: predicted:39, confidence=2130.2934260720194\n",
      "test_labels=10: predicted:10, confidence=1933.6064146494243\n",
      "test_labels=3: predicted:3, confidence=2824.110052876295\n",
      "test_labels=26: predicted:26, confidence=2307.4180015205225\n",
      "test_labels=8: predicted:8, confidence=1859.7845361055686\n",
      "test_labels=8: predicted:8, confidence=840.6126472121451\n",
      "test_labels=8: predicted:8, confidence=1771.477274197687\n",
      "test_labels=12: predicted:12, confidence=1865.8773196561021\n",
      "test_labels=3: predicted:3, confidence=2115.5226525561675\n",
      "test_labels=5: predicted:5, confidence=2092.785950883064\n",
      "test_labels=17: predicted:17, confidence=2148.765492637343\n",
      "test_labels=34: predicted:34, confidence=2117.095609118816\n",
      "test_labels=35: predicted:35, confidence=1782.45452748551\n",
      "test_labels=28: predicted:28, confidence=3265.04112271438\n",
      "test_labels=11: predicted:11, confidence=1929.60521925704\n",
      "test_labels=38: predicted:38, confidence=1564.4563468866859\n",
      "test_labels=15: predicted:15, confidence=1523.299926059252\n",
      "test_labels=7: predicted:7, confidence=2374.9659762446654\n",
      "test_labels=19: predicted:19, confidence=1587.4563256745057\n",
      "test_labels=27: predicted:27, confidence=822.4538179858802\n",
      "test_labels=18: predicted:18, confidence=2413.534481172429\n",
      "test_labels=34: predicted:34, confidence=2478.11777422283\n",
      "test_labels=10: predicted:10, confidence=1020.5411469664109\n",
      "accuracy= 0.9875\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#1\n",
    "WIDTH = 92\n",
    "HEIGHT = 112\n",
    "def load_face(filename='./data/faces.csv', test_ratio=0.2):\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    N = len(lines)\n",
    "    faces = np.empty((N, WIDTH*HEIGHT), dtype=np.uint8 )\n",
    "    labels = np.empty(N, dtype = np.int32)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        filename, label = line.strip().split(';')\n",
    "        labels[i] = int(label)\n",
    "        img = cv2.imread(filename[:2]+'data/'+filename[2:], cv2.IMREAD_GRAYSCALE) # unzip ./data/att_faces.zip\n",
    "        faces[i, :] = img.flatten()\n",
    "\n",
    "    # shuffling and seperate train and test data\n",
    "    indices = list(range(N))\n",
    "    random.seed(1) # same random sequences, so the same result\n",
    "    random.shuffle(indices)\n",
    "    shuffle_faces = faces[indices]\n",
    "    shuffle_labels = labels[indices]\n",
    "\n",
    "    test_size = int(test_ratio*N)\n",
    "\n",
    "    test_faces = shuffle_faces[:test_size]\n",
    "    test_labels = shuffle_labels[:test_size]\n",
    "\n",
    "    train_faces = shuffle_faces[test_size:]\n",
    "    train_labels = shuffle_labels[test_size:]\n",
    "    return train_faces, train_labels, test_faces, test_labels\n",
    "\n",
    "#2\n",
    "train_faces, train_labels, test_faces, test_labels = load_face()\n",
    "print('train_faces.shape=',  train_faces.shape)\n",
    "print('train_labels.shape=', train_labels.shape)\n",
    "print('test_faces.shape=',   test_faces.shape)\n",
    "print('test_labels.shape=',  test_labels.shape)\n",
    "\n",
    "#3    \n",
    "recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "##recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "recognizer.train(train_faces.reshape(-1, HEIGHT, WIDTH), train_labels)\n",
    "\n",
    "#4: display eigen Face\n",
    "eigenFace = recognizer.getEigenVectors()\n",
    "eigenFace = eigenFace.T\n",
    "print('eigenFace.shape=',  eigenFace.shape)\n",
    "\n",
    "dst = np.zeros((8*HEIGHT, 10*WIDTH), dtype=np.uint8)\n",
    "\n",
    "##for i in range(39): # FisherFaceRecognizer\n",
    "for i in range(80):\n",
    "    x = i%10\n",
    "    y = i//10\n",
    "    x1 = x*WIDTH\n",
    "    y1 = y*HEIGHT\n",
    "    x2 = x1+WIDTH\n",
    "    y2 = y1+HEIGHT  \n",
    "  \n",
    "    img = eigenFace[i].reshape(HEIGHT, WIDTH)\n",
    "    dst[y1:y2, x1:x2] = cv2.normalize(img,None,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "cv2.imshow('eigenFace 80', dst)\n",
    "\n",
    "#5: predict test_faces using recognizer\n",
    "correct_count = 0\n",
    "for i, face in enumerate(test_faces): \n",
    "    predict_label, confidence = recognizer.predict(face)\n",
    "    if test_labels[i]== predict_label:\n",
    "        correct_count+= 1\n",
    "    print('test_labels={}: predicted:{}, confidence={}'.format(\n",
    "                     test_labels[i], predict_label, confidence))\n",
    "    \n",
    "accuracy = correct_count / float(len(test_faces))\n",
    "print('accuracy=', accuracy)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 face recognition with AT&T Face Database 2: LBPHFaceRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_faces.shape= (320, 10304)\n",
      "train_labels.shape= (320,)\n",
      "test_faces.shape= (80, 10304)\n",
      "test_labels.shape= (80,)\n",
      "test_labels=20: predicted:20, confidence=63.53159239674068\n",
      "test_labels=15: predicted:15, confidence=56.76836690095442\n",
      "test_labels=26: predicted:26, confidence=65.35428328380661\n",
      "test_labels=33: predicted:33, confidence=78.94946641055041\n",
      "test_labels=38: predicted:38, confidence=75.97988206043449\n",
      "test_labels=21: predicted:21, confidence=82.08887829286003\n",
      "test_labels=32: predicted:32, confidence=84.18183984479495\n",
      "test_labels=34: predicted:34, confidence=72.16901863930305\n",
      "test_labels=0: predicted:0, confidence=78.75554190227402\n",
      "test_labels=28: predicted:28, confidence=63.16955227973658\n",
      "test_labels=5: predicted:5, confidence=69.28946916637393\n",
      "test_labels=4: predicted:4, confidence=64.63933640341054\n",
      "test_labels=3: predicted:3, confidence=66.44944519613094\n",
      "test_labels=28: predicted:28, confidence=73.32473172587548\n",
      "test_labels=22: predicted:22, confidence=61.721612437042324\n",
      "test_labels=19: predicted:19, confidence=72.6869564763709\n",
      "test_labels=23: predicted:23, confidence=70.08252144563349\n",
      "test_labels=30: predicted:30, confidence=73.68417603002699\n",
      "test_labels=10: predicted:10, confidence=64.87692069784792\n",
      "test_labels=21: predicted:21, confidence=68.60931018355592\n",
      "test_labels=6: predicted:6, confidence=62.42943779654621\n",
      "test_labels=32: predicted:32, confidence=72.38653452106406\n",
      "test_labels=38: predicted:38, confidence=56.316642002959085\n",
      "test_labels=2: predicted:2, confidence=68.48076569718461\n",
      "test_labels=9: predicted:9, confidence=68.16472800570462\n",
      "test_labels=16: predicted:16, confidence=68.61633816903462\n",
      "test_labels=31: predicted:31, confidence=69.23613385192938\n",
      "test_labels=38: predicted:38, confidence=58.249879241662676\n",
      "test_labels=35: predicted:35, confidence=63.59130641274919\n",
      "test_labels=10: predicted:10, confidence=57.28739592441953\n",
      "test_labels=3: predicted:3, confidence=66.29421647663028\n",
      "test_labels=37: predicted:37, confidence=64.80227136289078\n",
      "test_labels=2: predicted:2, confidence=67.04763300158947\n",
      "test_labels=9: predicted:9, confidence=70.57010266230759\n",
      "test_labels=8: predicted:8, confidence=67.25114029813888\n",
      "test_labels=30: predicted:30, confidence=69.76173278447251\n",
      "test_labels=34: predicted:13, confidence=87.57682723101284\n",
      "test_labels=8: predicted:8, confidence=71.04794581172273\n",
      "test_labels=12: predicted:12, confidence=61.47554788049576\n",
      "test_labels=26: predicted:26, confidence=78.54355391725223\n",
      "test_labels=22: predicted:22, confidence=73.91948275316803\n",
      "test_labels=33: predicted:33, confidence=62.47540709037265\n",
      "test_labels=34: predicted:35, confidence=86.52634471217993\n",
      "test_labels=23: predicted:23, confidence=67.77178986859664\n",
      "test_labels=13: predicted:13, confidence=70.04312613113598\n",
      "test_labels=30: predicted:30, confidence=66.81501615748402\n",
      "test_labels=25: predicted:25, confidence=64.21791860822599\n",
      "test_labels=26: predicted:26, confidence=72.50338916802869\n",
      "test_labels=37: predicted:37, confidence=69.99859890707056\n",
      "test_labels=30: predicted:30, confidence=64.63257168302847\n",
      "test_labels=39: predicted:39, confidence=73.21721325539515\n",
      "test_labels=28: predicted:28, confidence=87.95501110026858\n",
      "test_labels=5: predicted:5, confidence=67.40362084192925\n",
      "test_labels=35: predicted:35, confidence=65.28257013254459\n",
      "test_labels=18: predicted:18, confidence=68.15449331395266\n",
      "test_labels=15: predicted:15, confidence=67.6856704732354\n",
      "test_labels=25: predicted:25, confidence=66.1634956069417\n",
      "test_labels=39: predicted:39, confidence=66.6242563542645\n",
      "test_labels=10: predicted:10, confidence=60.68353110930176\n",
      "test_labels=3: predicted:3, confidence=68.81583016512818\n",
      "test_labels=26: predicted:26, confidence=71.17717358932501\n",
      "test_labels=8: predicted:8, confidence=68.15621119764268\n",
      "test_labels=8: predicted:8, confidence=58.33452946028829\n",
      "test_labels=8: predicted:8, confidence=61.24375663336904\n",
      "test_labels=12: predicted:12, confidence=67.64116227275328\n",
      "test_labels=3: predicted:3, confidence=65.24171492107168\n",
      "test_labels=5: predicted:5, confidence=63.04036885963557\n",
      "test_labels=17: predicted:17, confidence=70.51412910520007\n",
      "test_labels=34: predicted:34, confidence=73.36626728128859\n",
      "test_labels=35: predicted:35, confidence=72.71897099216419\n",
      "test_labels=28: predicted:28, confidence=80.63635251331333\n",
      "test_labels=11: predicted:11, confidence=61.85779561147603\n",
      "test_labels=38: predicted:38, confidence=57.0722691349092\n",
      "test_labels=15: predicted:15, confidence=67.59070210956943\n",
      "test_labels=7: predicted:7, confidence=67.61870739215279\n",
      "test_labels=19: predicted:19, confidence=60.2657618601104\n",
      "test_labels=27: predicted:27, confidence=60.327109180596864\n",
      "test_labels=18: predicted:18, confidence=74.12660136323477\n",
      "test_labels=34: predicted:34, confidence=80.59929453523937\n",
      "test_labels=10: predicted:10, confidence=56.43321379562106\n",
      "accuracy= 0.975\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#1\n",
    "WIDTH = 92\n",
    "HEIGHT = 112\n",
    "def load_face(filename='./data/faces.csv', test_ratio=0.2):\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    N = len(lines)\n",
    "    faces = np.empty((N, WIDTH*HEIGHT), dtype=np.uint8 )\n",
    "    labels = np.empty(N, dtype = np.int32)\n",
    "    for i, line in enumerate(lines):\n",
    "        filename, label = line.strip().split(';')\n",
    "        labels[i] = int(label)\n",
    "        img = cv2.imread(filename[:2]+'data/'+filename[2:], cv2.IMREAD_GRAYSCALE) # unzip ./data/att_faces.zip\n",
    "        faces[i, :] = img.flatten()\n",
    "\n",
    "    # shuffling and seperate train and test data\n",
    "    indices = list(range(N))\n",
    "    random.seed(1) # same random sequences, so the same result\n",
    "    random.shuffle(indices)\n",
    "    shuffle_faces = faces[indices]\n",
    "    shuffle_labels = labels[indices]\n",
    "\n",
    "    test_size = int(test_ratio*N)\n",
    "\n",
    "    test_faces = shuffle_faces[:test_size]\n",
    "    test_labels = shuffle_labels[:test_size]\n",
    "\n",
    "    train_faces = shuffle_faces[test_size:]\n",
    "    train_labels = shuffle_labels[test_size:]\n",
    "    return train_faces, train_labels, test_faces, test_labels\n",
    "\n",
    "train_faces, train_labels, test_faces, test_labels = load_face()\n",
    "print('train_faces.shape=',  train_faces.shape)\n",
    "print('train_labels.shape=', train_labels.shape)\n",
    "print('test_faces.shape=',   test_faces.shape)\n",
    "print('test_labels.shape=',  test_labels.shape)\n",
    "\n",
    "#2    \n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.train(train_faces.reshape(-1, HEIGHT, WIDTH), train_labels)\n",
    " \n",
    "#3: predict test_faces using recognizer\n",
    "correct_count = 0\n",
    "for i, face in enumerate(test_faces.reshape(-1, HEIGHT, WIDTH)):    \n",
    "    predict_label, confidence = recognizer.predict(face)\n",
    "    if test_labels[i]== predict_label:\n",
    "        correct_count+= 1\n",
    "    print('test_labels={}: predicted:{}, confidence={}'.format(\n",
    "                     test_labels[i], predict_label,confidence))\n",
    "    \n",
    "accuracy = correct_count / float(len(test_faces))\n",
    "print('accuracy=', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 face recognition with AT&T Face Database 3: build EigenFace without Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_faces.shape= (320, 10304)\n",
      "train_labels.shape= (320,)\n",
      "test_faces.shape= (80, 10304)\n",
      "test_labels.shape= (80,)\n",
      "mean.shape =  (1, 10304)\n",
      "eigenFace.shape= (80, 10304)\n",
      "Y.shape= (320, 80)\n",
      "test_labels=20: predicted:20\n",
      "test_labels=15: predicted:15\n",
      "test_labels=26: predicted:26\n",
      "test_labels=33: predicted:33\n",
      "test_labels=38: predicted:38\n",
      "test_labels=21: predicted:21\n",
      "test_labels=32: predicted:32\n",
      "test_labels=34: predicted:34\n",
      "test_labels=0: predicted:0\n",
      "test_labels=28: predicted:28\n",
      "test_labels=5: predicted:5\n",
      "test_labels=4: predicted:4\n",
      "test_labels=3: predicted:3\n",
      "test_labels=28: predicted:28\n",
      "test_labels=22: predicted:22\n",
      "test_labels=19: predicted:19\n",
      "test_labels=23: predicted:23\n",
      "test_labels=30: predicted:30\n",
      "test_labels=10: predicted:10\n",
      "test_labels=21: predicted:21\n",
      "test_labels=6: predicted:6\n",
      "test_labels=32: predicted:32\n",
      "test_labels=38: predicted:38\n",
      "test_labels=2: predicted:2\n",
      "test_labels=9: predicted:9\n",
      "test_labels=16: predicted:16\n",
      "test_labels=31: predicted:31\n",
      "test_labels=38: predicted:38\n",
      "test_labels=35: predicted:35\n",
      "test_labels=10: predicted:10\n",
      "test_labels=3: predicted:3\n",
      "test_labels=37: predicted:37\n",
      "test_labels=2: predicted:2\n",
      "test_labels=9: predicted:9\n",
      "test_labels=8: predicted:8\n",
      "test_labels=30: predicted:30\n",
      "test_labels=34: predicted:34\n",
      "test_labels=8: predicted:8\n",
      "test_labels=12: predicted:12\n",
      "test_labels=26: predicted:26\n",
      "test_labels=22: predicted:22\n",
      "test_labels=33: predicted:33\n",
      "test_labels=34: predicted:35\n",
      "test_labels=23: predicted:23\n",
      "test_labels=13: predicted:13\n",
      "test_labels=30: predicted:30\n",
      "test_labels=25: predicted:25\n",
      "test_labels=26: predicted:26\n",
      "test_labels=37: predicted:37\n",
      "test_labels=30: predicted:30\n",
      "test_labels=39: predicted:39\n",
      "test_labels=28: predicted:28\n",
      "test_labels=5: predicted:5\n",
      "test_labels=35: predicted:35\n",
      "test_labels=18: predicted:18\n",
      "test_labels=15: predicted:15\n",
      "test_labels=25: predicted:25\n",
      "test_labels=39: predicted:39\n",
      "test_labels=10: predicted:10\n",
      "test_labels=3: predicted:3\n",
      "test_labels=26: predicted:26\n",
      "test_labels=8: predicted:8\n",
      "test_labels=8: predicted:8\n",
      "test_labels=8: predicted:8\n",
      "test_labels=12: predicted:12\n",
      "test_labels=3: predicted:3\n",
      "test_labels=5: predicted:5\n",
      "test_labels=17: predicted:17\n",
      "test_labels=34: predicted:34\n",
      "test_labels=35: predicted:35\n",
      "test_labels=28: predicted:28\n",
      "test_labels=11: predicted:11\n",
      "test_labels=38: predicted:38\n",
      "test_labels=15: predicted:15\n",
      "test_labels=7: predicted:7\n",
      "test_labels=19: predicted:19\n",
      "test_labels=27: predicted:27\n",
      "test_labels=18: predicted:18\n",
      "test_labels=34: predicted:34\n",
      "test_labels=10: predicted:10\n",
      "accuracy= 0.9875\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#1\n",
    "WIDTH = 92\n",
    "HEIGHT = 112\n",
    "def load_face(filename='./data/faces.csv', test_ratio=0.2):\n",
    "    file = open(filename, 'r')\n",
    "    lines = file.readlines()\n",
    "\n",
    "    N = len(lines)\n",
    "    faces = np.empty((N, WIDTH*HEIGHT), dtype=np.uint8 )\n",
    "    labels = np.empty(N, dtype = np.int32)\n",
    "    for i, line in enumerate(lines):\n",
    "        filename, label = line.strip().split(';')\n",
    "        labels[i] = int(label)\n",
    "        img = cv2.imread(filename[:2]+'data/'+filename[2:], cv2.IMREAD_GRAYSCALE) # unzip ./data/att_faces.zip\n",
    "        faces[i, :] = img.flatten()\n",
    "\n",
    "    # shuffling and seperate train and test data\n",
    "    indices = list(range(N))\n",
    "    random.seed(1) # same random sequences, so the same result\n",
    "    random.shuffle(indices)\n",
    "    shuffle_faces = faces[indices]\n",
    "    shuffle_labels = labels[indices]\n",
    "\n",
    "    test_size = int(test_ratio*N)\n",
    "\n",
    "    test_faces = shuffle_faces[:test_size]\n",
    "    test_labels = shuffle_labels[:test_size]\n",
    "\n",
    "    train_faces = shuffle_faces[test_size:]\n",
    "    train_labels = shuffle_labels[test_size:]\n",
    "    return train_faces, train_labels, test_faces, test_labels\n",
    "\n",
    "train_faces, train_labels, test_faces, test_labels = load_face()\n",
    "print('train_faces.shape=',  train_faces.shape)\n",
    "print('train_labels.shape=', train_labels.shape)\n",
    "print('test_faces.shape=',   test_faces.shape)\n",
    "print('test_labels.shape=',  test_labels.shape)\n",
    "\n",
    "#2\n",
    "N = 80\n",
    "mean, eigenFace = cv2.PCACompute(train_faces, mean=None, maxComponents=N)\n",
    "print('mean.shape = ', mean.shape)\n",
    "print('eigenFace.shape=',  eigenFace.shape)\n",
    "\n",
    "Y = cv2.PCAProject(train_faces, mean, eigenFace) # train result\n",
    "print('Y.shape=', Y.shape)\n",
    "\n",
    "#3: display eigen Face\n",
    "dst = np.zeros((8*HEIGHT, 10*WIDTH), dtype=np.uint8)\n",
    "for i in range(N):\n",
    "    x = i%10\n",
    "    y = i//10\n",
    "    x1 = x*WIDTH\n",
    "    y1 = y*HEIGHT\n",
    "    x2 = x1+WIDTH\n",
    "    y2 = y1+HEIGHT  \n",
    "  \n",
    "    img = eigenFace[i].reshape(HEIGHT, WIDTH)\n",
    "    dst[y1:y2, x1:x2] = cv2.normalize(img,None,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "cv2.imshow('eigenFace %s'%N, dst)\n",
    "\n",
    "#4: predict test_faces using  y = eigenFace(face - mean) and min distance\n",
    "correct_count = 0\n",
    "for i, face in enumerate(test_faces): \n",
    "    y =cv2.PCAProject(face.reshape(1,-1), mean, eigenFace)\n",
    "    dist=np.sqrt(np.sum((Y-y)**2,axis=1))\n",
    "    k = np.argmin(dist)\n",
    "    predict_label = train_labels[k]\n",
    "\n",
    "    if test_labels[i]== predict_label:\n",
    "        correct_count+= 1\n",
    "    print('test_labels={}: predicted:{}'.format(\n",
    "                     test_labels[i], predict_label))\n",
    "    \n",
    "accuracy = correct_count / float(len(test_faces))\n",
    "print('accuracy=', accuracy)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
